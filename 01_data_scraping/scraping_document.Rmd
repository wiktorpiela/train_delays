---
title: "Opóźnienia pociagów"
author: "Wiktor Piela"
date: "`r Sys.Date()`"
output: 
  prettydoc::html_pretty:
    theme: cayman
#always_allow_html: true
#pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      error = FALSE,
                      warning = FALSE,
                      message = FALSE)
library("tidyverse")
library("reticulate")
library("kableExtra")
library("leaflet")
setwd("C:/Users/wpiel/OneDrive/Desktop/opoznienia_pociagow/02_data_scraping")
cities <- readxl::read_excel("miasta_slownik.xlsx")
```

```{r graphic, out.height="30%"}
knitr::include_graphics("IMG_0375-Copy-1170x612.jpg")
```

## Wstęp i cel badania

Na stronie internetowej <https://infopasazer.intercity.pl/> udostępniane są informacje na temat aktywnych połączeń kolejowych w czasie rzeczywistym realizowanych zarówno przez regionalnych przewoźników jak i PKP Intercity. Pasażerowie mogą sprawdzić gdzie aktualnie znajduje się interesujący ich pociąg oraz ewentualne prognozowane opóźnienie jego przyjazdu do okreslonej stacji. Ponadto, poziom szczegółowości prezentowanych danych pozwala na sprawdzenie liczby przystanków, a także godzinę planowego przyjazdu i odjazdu na każdej z nich.

Zebranie odpowiedniej ilości takich danych pozwoliłoby pomóc w szukaniu odpowiedzi na pytanie - co wpływa na opóźnienia pociągów w Polsce? Dodatkowo - przy pomocy modelowania styatystycznego i zebranym danym można byłoby pokusić się o predykcję - czy i ile minut dana relacja będzie opóźniona - a zatem, jakie cechy połączenia kolejowego mogłby sugerować, że przyjedzie ono do stacji końcowej z okreslonym opóźnieniem.

## Metodologia pozyskiwania danych i założenia badania

Niemożliwe byłoby pozyskanie danych o absolutnie wszystkich połączeniach kolejowych mających miejsce na teerenie Polski w danym okresie - zatem, dość intuicyjnym pomysłem byłoby zebranie odpowiedniej próby. Dla celów tego badania zostaną pozyskane dane o połączeniach przejeżdzających przez dworce główne 16 wybranych miast w Polsce - zarówno loklanych jak i ogólnopolskich. 

```{r polmap, fig.align='center'}
geo <- tibble(
  miasta = cities$miasto,
  lat = c(51.110,50.060,52.259,53.430,50.049,54.360,51.770,
          54.189,52.399,50.529,53.139,50.810,51.240,53.120,53.779,54.520),
  lon = c(17.030,19.959,21.020,14.529,21.999,18.639,19.459,
          15.569,16.900,19.020,23.159,19.192,22.570,18.010,20.489,18.530)
  )
leaflet(geo) %>% 
  addTiles %>% 
  setView(lng = 19.316373, lat = 52.304989, zoom = 6) %>% 
  addMarkers(lng = ~lon, 
             lat = ~lat,
             popup = ~miasta,
             options = popupOptions(closeButton = FALSE))
```

Miasta zostały dobrane w taki sposób, aby były jednymi z większych miast w swoich regionach oraz były równomiernie rozłożone na terenie Polski. Dworce główne w większych miastach obsługują najwięcej pasażerów, zatem próba danych pochodząca z tym miast powinna być reprezentatywna, a dalsze wnioski wynikające z danych będa odnosiły się do największego odsetka pasażerów podróżujących polskimi kolejami.

Wspomniana wcześniej strona internetowa nie pozwala jednak na wybranie kilku stacji jednocześnie, dlatego w celu uzyskania aktywnych połączeń ze wszystkich stacji, program zbierający dane będzie musiał iteracyjnie otworzyć strony dla wszystkich 16 stacji oddzielnie - każda z nich ma swoje id, co ułatwia zadanie.

```{r cities_table}
kable(
  tibble(
  miasto = "id"
  ) %>% 
    bind_cols(cities %>% 
              pivot_wider(names_from = miasto,
                          values_from = id)),
  caption = "") %>% 
  kable_classic(full_width = FALSE, html_font = "TimesNewRoman") %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  scroll_box(width = "900px")
```

## Zasada działania algorytmu zbierania danych

Zbieranie danych takiej skali oraz ilości to nie jest zadanie manualne. Interesuje nas bowiem zebranie jak najwiekszej ilości danych w zadanym okresie oraz obszarze. Nawet ograniczając się do samej próby - codziennie w Polsce odbywają się setki kursów, w ciągu dnia,a także w nocy. Trudno zatem wyobrazić sobie, żeby ktoś całą dobę zajmował się tylko pozyskiwaniem tych danych i to przez pewien okres czasu. Ponadto, często zdarza się sytuacja, że kilka pociagów kończy bieg dokładnie o tej samej godzinie w różnych cześciach kraju, a strona przechowuje informacje tylko o aktywnych połączeniach, zatem znikają informacje o nich po godzinie przyjazdu. Ten fakt tym bardziej uniemożliwia ręczne scrapowanie danych.

W tym celu zaprojektowany został schemat pozyskiwania danych wraz z narzędziem zaimplementowanym w języku Python -  <https://github.com/wiktorpiela/train_delays/blob/main/01_data_scraping/scraper.py>

**Działa ono dwuetapowo:**

1. Etap I
a. po pierwsze, funkcja `get_trains()` zasilana jest wcześniej zdefiniowanym słownikiem miasto-id. Iteracyjnie przechodzi po stronach z aktywnymi relacjami wszystkich miasts pozyskując odnośniki do stron z konkretnymi połączeniami
a. następnie, usunięte zostają duplikaty, tak, aby pociąg przejeżdzający przez więcej niż jedno miasto z listy pojawił sie tylko raz 
a. uzyskanie informacji o przyjeżdzie do stacji końcowej każdej relacji, bo dokładnie wtedy ostatecznie scrapowane będą dane
a. konieczność korekty błędu właściciela strony - pociąg wyjeżdzający wieczorem danego dnia a przyjeżdżający do stacji końcowej po północy posiada datę wyjazdu (np. wyjazd 28.10.2022 godz. 19:50, przyjazd 28.10.2022 godz. 00:12)
a. wprowadzenie losowego szumu do dokładnej chwili przyjazdu, aby uniknąć kolizji w przypadku pozyskiwania danych dokładnie o tej samej godzinie co do sekundy
a. filtrowanie połączeń - wybór tylko przyszłych, ale nie dalszych niż 24 godziny - wtedy następi kolejna iteracja zadania
a. ostatecznie funkcja `get_trains()` zwraca listę tupli, każda tupla zawiera bezpośredni link do połączenia wraz z dokładną godziną przyjazdu

2. Etap II
a. funkcji `scrape_data()` dostarczany jest argument w postaci wygenerowanej listy tupli przez wcześniejszą funkcję - iteruje ona po tej liście, pozyskując dane o połaczeniu o dokładnej godzinie
a. takie dane zapisywane są lokalnie do pliku `.parquet` o nazwie godziny pobrania z dodatkowym suffixem, aby zminimalizować ryzyko tej pojawienia się tej samej nazwy dla więcej niż jednego pliku, a co za tym idzie, nadpisania pierwszego z nich
a. w ciele funkcji znajduje się także wątek dotyczący obsługi błedów, aby program nie przestał pracować wobec ewentualnego nie napotkania tabeli pod odnośnikiem do relacji 



